{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7febb158",
   "metadata": {},
   "source": [
    "# CAPSTONE PROJECT - 8\n",
    "\n",
    "### Domain: \n",
    "#### Financial Services\n",
    "### Title:\n",
    "#### Exploratory Data Analysis and Credit Assessment in Financial Services\n",
    "\n",
    "### About:\n",
    "#### Finance is a field that is concerned with the allocation (investment) of assets and liabilities over space and time, often under conditions of risk or uncertainty. Finance can also be defined as the art of money management. Participants in the market aim to price assets based on their risk level, fundamental value, and their expected rate of return.\n",
    "#### The dataset consists of customer information on L&T financial services. It is a finance dataset, which consists of customers’ demographics, loans disbursed, asset cost being purchased, and the customers’ previous accounts and loan histories. The dataset also consists of the state and branch id of L&T from where the loan was disbursed and the customer’s account history. It also contains the CNS score and score description provided by the Credit Bureaus of India.\n",
    "#### It is a challenge for any financial service to target the right people for disbursing the loan. The credit team must analyze various details like CIBIL score, payment history (if available), credit history, geographical location, profession, income, age, education, etc. of the customers. This will help in understanding whether the person is capable of paying back the loan amount. Which in turn reduces its NPAs and increases its profitability.\n",
    "#### You need to assess what data is available and perform some exploratory and descriptive analytics to identify interesting and useful patterns, trends, and insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f04d09",
   "metadata": {},
   "source": [
    "\n",
    "## CheckPoint 1\n",
    "\n",
    "#### Task 1.1 Data manipulation and Visualization using Python\n",
    "#### Task 1.2 Exploratory Data Analysis & Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93531f09",
   "metadata": {},
   "source": [
    "## Task 1.1 Data manipulation and Visulization using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30610329",
   "metadata": {},
   "source": [
    "### Step A & B\n",
    "- Load the dataset: Import the dataset into a Python environment (e.g., using pandas library) and create a data frame.\n",
    "\n",
    "- Data exploration: Perform initial exploration of the dataset to gain insights into its structure and content. Use functions such as .head(), .info(), .describe(), and .shape to understand the data's dimensions, variable types, and summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428437d",
   "metadata": {},
   "source": [
    "#### Importing the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821f6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ef761",
   "metadata": {},
   "source": [
    "#### Loading the datasets into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "665e68c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\compat\\_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoan_status_mapping.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m branch_id \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBranch_ID_Master.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m postal_code \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPostal_Code_Master.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m city_master \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCity_Master.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m region_master \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegion_Master.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:1580\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1584\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\excel\\_openpyxl.py:552\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    539\u001b[0m     engine_kwargs: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    540\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;124;03m        Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 552\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    554\u001b[0m         filepath_or_buffer,\n\u001b[0;32m    555\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    556\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    557\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\compat\\_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "loan_details = pd.read_csv(\"Loan_Details_transactions.csv\")\n",
    "df2 = pd.read_csv(\"Loan_status_mapping.csv\")\n",
    "branch_id = pd.read_csv(\"Branch_ID_Master.csv\")\n",
    "postal_code = pd.read_excel(\"Postal_Code_Master.xlsx\" )\n",
    "city_master = pd.read_excel(\"City_Master.xlsx\")\n",
    "region_master = pd.read_excel(\"Region_Master.xlsx\")\n",
    "state_master = pd.read_excel(\"State_Master.xlsx\")\n",
    "state_region = pd.read_excel(\"State_Region_Mapping.xlsx\")\n",
    "df3 = df2.drop(['Loan_Id'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ea8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(loan_details, city_master, on=['City_Code', 'State_Code'], how='left')\n",
    "merged_df1 = pd.merge(merged_df,state_master, on=['State_Code'], how='left')\n",
    "merged_df2 = pd.merge(merged_df1,branch_id, on=['Branch_Id'], how='left')\n",
    "merged_df3 = pd.merge(merged_df2,state_region[['Region_ID','State_Code']], on=['State_Code'], how='left')\n",
    "\n",
    "loan_details = pd.concat([merged_df3,df3],axis=1)\n",
    "loan_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d5e756",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a08092",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfcd9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e93c82",
   "metadata": {},
   "source": [
    "#### All the numeric data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_type = loan_details.select_dtypes(include=['int64','float64']).columns\n",
    "print(pd.DataFrame(numeric_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed0b2ed",
   "metadata": {},
   "source": [
    "#### All the catagorical data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1be28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_type = loan_details.select_dtypes(include='object').columns\n",
    "print(pd.DataFrame(objects_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49356e",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "#### Checking for any duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details[loan_details.duplicated].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b1ad0f",
   "metadata": {},
   "source": [
    "#### Checking for missing values under each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a7d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96814f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total missing values\n",
    "loan_details.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Percentage of missing values \n",
    "(loan_details.isnull().sum().sum()/len(loan_details))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b362ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the missing value with the mode \n",
    "loan_details['Employment_Type'].fillna(loan_details['Employment_Type'].mode()[0],inplace=True)\n",
    "loan_details['Region_ID'].fillna(loan_details['Region_ID'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f693a6",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe134b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate = loan_details.drop(['Loan_Id','Disbursed_Amount','Asset_Cost','ltv','Date_of_Birth','DisbursalDate',\n",
    "         'CREDIT.HISTORY.LENGTH', 'PERFORM_CNS.SCORE'],axis = 1)\n",
    "univariate.hist(figsize=(20,10),color = 'orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a5146",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf9a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing scatter plot for disbursed amount and asset cost\n",
    "\n",
    "plt.scatter(loan_details['Disbursed_Amount'] , loan_details['Asset_Cost'],linewidths = 0.71,\n",
    "            marker =\"s\",edgecolor =\"orange\",s = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "var =pd.crosstab(loan_details['Employment_Type'], loan_details['Loan_Default'])\n",
    "var.div(var.sum(0).astype(float),axis=0).plot(kind=\"bar\",stacked=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abb599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var =pd.crosstab(loan_details['Aadhar_flag'], loan_details['Loan_Default'])\n",
    "var.div(var.sum(0).astype(float),axis=1).plot(kind=\"bar\",stacked=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340d2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(50, 15))\n",
    "sns.boxplot(loan_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7022fdb",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf5c05",
   "metadata": {},
   "source": [
    "#### Outlier detection and handling (Disbursed_Amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf27c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(loan_details['Disbursed_Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding number of outliers using the interquantile range\n",
    "\n",
    "q1 = np.quantile(loan_details['Disbursed_Amount'],0.25)\n",
    "q3 = np.quantile(loan_details['Disbursed_Amount'],0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - (1.5 * iqr)\n",
    "print(lower_bound)\n",
    "higher_bound = q3 + (1.5* iqr)\n",
    "print(higher_bound)\n",
    "\n",
    "median = loan_details['Disbursed_Amount'].median()\n",
    "print(\"Median: \",median)\n",
    "loan_details[(loan_details['Disbursed_Amount'] > higher_bound) | (loan_details['Disbursed_Amount'] < lower_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa84b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(data,median):\n",
    "    cleaned_data = [median if val < lower_bound or val > higher_bound else val for val in data]\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56734247",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_disbursed = pd.DataFrame(replace(loan_details['Disbursed_Amount'] , median))\n",
    "new_disbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_details['Disbursed_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01baa2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details.insert(1, 'Disbursed_Amount',new_disbursed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c16e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(loan_details['Disbursed_Amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdf6140",
   "metadata": {},
   "source": [
    "#### Outlier detection and handling (Asset_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.quantile(loan_details['Asset_Cost'],0.25)\n",
    "q3 = np.quantile(loan_details['Asset_Cost'],0.75)\n",
    "iqr = q3 - q1\n",
    "lower_asset = q1 - (1.5 * iqr)\n",
    "print(lower_asset)\n",
    "higher_asset = q3 + (1.5* iqr)\n",
    "print(higher_asset)\n",
    "print(loan_details['Asset_Cost'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(data,median):\n",
    "    cleaned_data = [median if val < lower_asset or val > higher_asset else val for val in data]\n",
    "    return cleaned_data\n",
    "\n",
    "new_asset = pd.DataFrame(replace(loan_details['Asset_Cost'] , median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c92ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_details['Asset_Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd30432",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details.insert(2, 'Asset_Cost',new_asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b712e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(loan_details['Asset_Cost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9e1df",
   "metadata": {},
   "source": [
    "#### Changing the date to month in CREDIT.HISTORY.LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(i):\n",
    "    parts = i.split()\n",
    "    year = ''\n",
    "    month = ''\n",
    "    for j in parts[0]:\n",
    "        if j == '0' or j == '1' or j == '2' or j == '3' or j == '4' or j == '5' or j == '6' or j == '7' or j == '8' or j == '9':\n",
    "            year = year +j\n",
    "    year = int(year)\n",
    "    for j in parts[1]:\n",
    "        if j == '0' or j == '1' or j == '2' or j == '3' or j == '4' or j == '5' or j == '6' or j == '7' or j == '8' or j == '9':\n",
    "            month =month + j\n",
    "    month = int(month)\n",
    "    return (year * 12) + month\n",
    "data1 = loan_details['CREDIT.HISTORY.LENGTH'].tolist()\n",
    "months = [convert(i) for i in data1]\n",
    "new = pd.DataFrame(months)\n",
    "\n",
    "loan_details.drop(['CREDIT.HISTORY.LENGTH'] , axis = 1 ,inplace = True)\n",
    "loan_details.insert(16, 'CREDIT.HISTORY.LENGTH',new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1533a438",
   "metadata": {},
   "source": [
    "#### Changing the Date_of_Birth into year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details['Date_of_Birth']=pd.to_datetime(loan_details.Date_of_Birth)\n",
    "loan_details['Date_of_Birth']=loan_details['Date_of_Birth'].dt.year\n",
    "loan_details=loan_details.drop('DisbursalDate',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details['Region_ID'].fillna(loan_details['Region_ID'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88989e6a",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = loan_details.columns\n",
    "object_columns = []\n",
    "for column in columns:\n",
    "    if(loan_details[column].dtype == 'object'):\n",
    "        object_columns.append(column)\n",
    "        \n",
    "binary_columns = []\n",
    "odinary_columns = []\n",
    "for column in object_columns:\n",
    "    if(loan_details[column].unique().all() in ['yes','no']):\n",
    "        binary_columns.append(column)\n",
    "    else:\n",
    "        odinary_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "loan_details[odinary_columns] = encoder.fit_transform(loan_details[odinary_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee31ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details=loan_details.drop(['MobileNo_Avl_Flag'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc29779",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23820a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = loan_details.corr()\n",
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = loan_details.corr()\n",
    "plt.subplots(figsize=(20,22))\n",
    "sns.heatmap(matrix,vmax=.8,square=True,cmap='coolwarm', annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f971ad81",
   "metadata": {},
   "source": [
    "## CheckPoint 2\n",
    "\n",
    "#### Task 2.1 (Visualization using Power-BI Dashboard)\n",
    "#### Task 2.2 (Model building using ML algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa49231",
   "metadata": {},
   "source": [
    "## Hypothethis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12671acc",
   "metadata": {},
   "source": [
    "#### Hypothesis 1 : The average credit history length of borrowers who own a passport is significantly different from those who don't have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737db95c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_details['Passport_flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_history_passport = loan_details[loan_details['Passport_flag'] == 1]['CREDIT.HISTORY.LENGTH']\n",
    "credit_history_passport.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51fc522",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_history_no_passport = loan_details[loan_details['Passport_flag'] == 0]['CREDIT.HISTORY.LENGTH']\n",
    "credit_history_no_passport.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9251fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we will calculate mean and std. deviation for the customer havng passport\n",
    "mean_credit_history_passport = credit_history_passport.mean()\n",
    "std_credit_history_passport = credit_history_passport.std()\n",
    "\n",
    "## Then we will calculate the mean and std. deviation of customer not having passport\n",
    "mean_credit_history_no_passport = credit_history_no_passport.mean()\n",
    "std_credit_history_no_passport = credit_history_no_passport.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e09e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform the t-test for independent samples\n",
    "t_stat, p_value = stats.ttest_ind(credit_history_passport, credit_history_no_passport, equal_var=False)\n",
    "\n",
    "# We determine the significance of the test and interpret the results\n",
    "alpha = 0.05 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Credit History Length for Borrowers with Passport: {mean_credit_history_passport:.2f}\")\n",
    "print(f\"Mean Credit History Length for Borrowers without Passport: {mean_credit_history_no_passport:.2f}\")\n",
    "print(f\"T-statistic: {t_stat:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3702b6",
   "metadata": {},
   "source": [
    "#### Checking the hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_value < alpha:\n",
    "    print(\"The p-value is less than the significance level, Reject the null hypothesis.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than the significance level, Fail to reject the null hypothesis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eaa6d2",
   "metadata": {},
   "source": [
    "#### Hypothesis 2 : There is a significant difference in the mean ltv(loan to value ratio) between Self-employed borrowers and Salaried borrowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_details['Employment_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56972073",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltv_self_employed = loan_details[loan_details['Employment_Type'] == 0]['ltv']\n",
    "ltv_self_employed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a631854",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltv_salaried = loan_details[loan_details['Employment_Type'] == 1]['ltv']\n",
    "ltv_salaried.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2eefc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ltv_self_employed = ltv_self_employed.mean()\n",
    "std_ltv_self_employed = ltv_self_employed.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ltv_salaried = ltv_salaried.mean()\n",
    "std_ltv_salaried = ltv_salaried.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = stats.ttest_ind(ltv_self_employed, ltv_salaried, equal_var=False)\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e302ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean ltv for Self-employed: {mean_ltv_self_employed:.2f}\")\n",
    "print(f\"Mean ltv for Salaried: {mean_ltv_salaried:.2f}\")\n",
    "print(f\"T-statistic: {t_stat:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b007b93a",
   "metadata": {},
   "source": [
    "#### Checking the hypothethis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_value < alpha:\n",
    "    print(\"The p-value is less than the significance level . Reject the null hypothesis.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than the significance level . Fail to reject the null hypothesis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18662a3c",
   "metadata": {},
   "source": [
    "## Model Creation and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1528601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregation the data in two parts X and y\n",
    "new_loan_details = loan_details\n",
    "X = new_loan_details.drop(columns=['Loan_Default'],axis=1)   # independent variable\n",
    "y = new_loan_details['Loan_Default']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf8c56",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29019634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84650bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score (X_train_prediction,y_train)\n",
    "print('Accuracy score on training data : ',training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66014109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score on test data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "accuracy = accuracy_score (X_test_prediction,y_test)\n",
    "print('Accuracy score on test data:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a40eb",
   "metadata": {},
   "source": [
    "#### Logistic Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20779587",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix=confusion_matrix(y_test, X_test_prediction)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c425e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, X_test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b461b13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TN,FP,FN,TP=cnf_matrix.ravel()\n",
    "print(TN,FP,FN,TP)\n",
    "linear_test_data_accuracy=accuracy_score(y_test, X_test_prediction)\n",
    "print('Accuracy_score',linear_test_data_accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f4af9",
   "metadata": {},
   "source": [
    "#### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c61601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KFold with the desired number of splits\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "smote=SMOTE(sampling_strategy='auto',random_state=42)\n",
    "LR = LogisticRegression()\n",
    "\n",
    "# perform k-fold cross-validation using  logistic regression\n",
    "LR_metric=cross_val_score(LR,X,y,cv=kf)\n",
    "print(LR_metric)\n",
    "\n",
    "# calculate the average performance\n",
    "kFold_accuracy=LR_metric.mean()*100.0\n",
    "print(\"Accuracy: \",kFold_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6893ee",
   "metadata": {},
   "source": [
    "#### Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f86d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_loan_details.drop(columns=['Loan_Default'],axis=1)   # independent variable\n",
    "y = new_loan_details['Loan_Default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b411d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic imbalanced dataset\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print('Before applying smote method: ',X_train.shape)\n",
    "# Apply SMOTE to balance the classes in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print('After applying smote method: ',X_train_resampled.shape)\n",
    "# Train a model on the resampled training data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix=confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b62a39f",
   "metadata": {},
   "source": [
    "#### Smote Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8130e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN,FP,FN,TP=cnf_matrix.ravel()\n",
    "print(TN,FP,FN,TP)\n",
    "smote_Accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy_score: ',smote_Accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8746f80d",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d522216",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy by Linear Regression: ',round(linear_test_data_accuracy*100,3))\n",
    "print('Accuracy by Linear Regression with smote : ',round(smote_Accuracy*100,3))\n",
    "print('Accuracy by KFold: ',round(kFold_accuracy,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a47f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
